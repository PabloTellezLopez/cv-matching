{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Matching CVs con Red Neuronal creada desde 0"
      ],
      "metadata": {
        "id": "M3lfalln5EjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Carga y Preparación de Datos"
      ],
      "metadata": {
        "id": "UXE3YYUv5Lxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Montaje de Google Drive"
      ],
      "metadata": {
        "id": "t5FLKE6i7Zm6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "8mX80Ksk4SiV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65278417-d0a2-41a4-ebaa-5cc55afd8807"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# ─── MONTAJE DE GOOGLE DRIVE ─────────────────────────────────────────────\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición de rutas y mapping"
      ],
      "metadata": {
        "id": "0fR1ardQh5D6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── IMPORTS ──────────────────────────────────────────────────────────────\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Ruta a la carpeta con los archivos CSV\n",
        "BASE_PATH = \"/content/drive/MyDrive/TFM/red_neuronal/interim\""
      ],
      "metadata": {
        "id": "-QBWrNDz5e18"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAPPING = {\n",
        "    'cdatos':    'Ciencia_de_datos',\n",
        "    'ingdatos':  'Ingeniero_de_datos',\n",
        "    'jurista':   'Jurista',\n",
        "    'traductor': 'Traductor_de_inglés'\n",
        "}\n",
        "\n",
        "MAX_TOKENS = 300"
      ],
      "metadata": {
        "id": "vZSlFMDK5kon"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga de CVs y ofertas"
      ],
      "metadata": {
        "id": "qS5qoXkaiJWP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cvs(path, mapping):\n",
        "    df = pd.read_csv(path)\n",
        "\n",
        "    # Filtrar solo nombres que tengan uno de los códigos válidos\n",
        "    mask = df['Nombre del archivo'].str.contains(r'_(cdatos|ingdatos|jurista|traductor)_')\n",
        "    df_validos = df[mask].copy()\n",
        "    df_invalidos = df[~mask]['Nombre del archivo'].tolist()\n",
        "\n",
        "    if df_invalidos:\n",
        "        print(\"Se excluyen estos nombres de archivo (no parecen CVs válidos):\")\n",
        "        print(\"\\n\".join(df_invalidos))\n",
        "\n",
        "    # Ahora sí extraemos el código solo de los válidos\n",
        "    df_validos['code'] = df_validos['Nombre del archivo'].str.extract(r'_(cdatos|ingdatos|jurista|traductor)_')[0]\n",
        "    df_validos['category'] = df_validos['code'].map(mapping)\n",
        "\n",
        "    # Si hay algo que no mapeó, lo advertimos\n",
        "    unmapped = df_validos['category'].isna()\n",
        "    if unmapped.any():\n",
        "        bad = df_validos.loc[unmapped, 'Nombre del archivo'].tolist()\n",
        "        raise ValueError(\"Estos CVs tienen un código válido pero no están en MAPPING:\\n\" +\n",
        "                         \"\\n\".join(bad))\n",
        "\n",
        "    df_validos = df_validos.rename(columns={'Texto extraído': 'cv_text', 'Nombre del archivo': 'cv_id'})\n",
        "    return df_validos[['cv_id', 'cv_text', 'category']]\n",
        "\n",
        "def load_offers(offer_files):\n",
        "    offers = []\n",
        "    for cat, fp in offer_files.items():\n",
        "        df = pd.read_csv(fp).rename(columns={'descripcion_oferta': 'offer_text'})\n",
        "        df['offer_id'] = df.index.astype(str) + f'_{cat}'\n",
        "        df['offer_category'] = cat\n",
        "        offers.append(df[['offer_id', 'offer_text', 'offer_category']])\n",
        "    return pd.concat(offers, ignore_index=True)"
      ],
      "metadata": {
        "id": "ZqbpDpZFkxIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se cargan los archivos CSV de currículums (CVs) y ofertas de empleo.\n",
        "\n",
        "En el caso de los CVs:\n",
        "\n",
        "- Se filtran solo los archivos cuyo nombre contiene un código de categoría válido\n",
        "\n",
        "- Se verifica que todos los códigos extraídos tengan una correspondencia en el diccionario `MAPPING`.\n",
        "\n",
        "- Se lanza un error si se detectan CVs con códigos válidos pero no definidos en el `MAPPING`.\n",
        "\n",
        "En el caso de las ofertas, se construye un identificador único por oferta y se etiqueta cada una con su categoría correspondiente.\n",
        "\n",
        "Esto garantiza que solo se trabajará con ejemplos consistentes y etiquetados correctamente."
      ],
      "metadata": {
        "id": "Kqqy7vVaqneG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── CARGA DE DATOS ───────────────────────────────────────────────────────\n",
        "# CVs de entrenamiento\n",
        "cvs_path = os.path.join(BASE_PATH, \"cvs_train_preprocesado.csv\")\n",
        "df_cvs = load_cvs(cvs_path, MAPPING)\n",
        "\n",
        "# Ofertas por categoría\n",
        "offer_files = {\n",
        "    'Ciencia_de_datos': os.path.join(BASE_PATH, 'Ciencia_de_datos_España_ofertas.csv'),\n",
        "    'Ingeniero_de_datos': os.path.join(BASE_PATH, 'Ingeniero_de_datos_España_ofertas.csv'),\n",
        "    'Traductor_de_inglés': os.path.join(BASE_PATH, 'Traductor_de_inglés_Málaga_ofertas.csv'),\n",
        "    'Jurista': os.path.join(BASE_PATH, 'Jurista_Málaga_ofertas.csv')\n",
        "}\n",
        "\n",
        "offers = load_offers(offer_files)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHKD0ud15ymn",
        "outputId": "61fe8522-93ab-4efa-c4e8-fd3667c691ea"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Se excluyen estos nombres de archivo (no parecen CVs válidos):\n",
            "CV_numeropdf_oferta_numerooferta.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-727503ea7a93>:6: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
            "  mask = df['Nombre del archivo'].str.contains(r'_(cdatos|ingdatos|jurista|traductor)_')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creación de pares CV-oferta"
      ],
      "metadata": {
        "id": "Ir60eLFfibnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_pairs(df_cvs, df_offers):\n",
        "    df_cvs = df_cvs.assign(key=1)\n",
        "    df_offers = df_offers.assign(key=1)\n",
        "    pairs = df_cvs.merge(df_offers, on='key').drop('key', axis=1)\n",
        "    pairs['label'] = (pairs['category'] == pairs['offer_category']).astype(int)\n",
        "    return pairs.rename(columns={'category':'cv_category'})"
      ],
      "metadata": {
        "id": "qvre7BOyk3WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se genera el conjunto de entrenamiento combinando todos los CVs con todas las ofertas mediante un producto cartesiano.\n",
        "\n",
        "Cada par CV-oferta recibe una etiqueta binaria:\n",
        "- `label = 1` si la categoría del CV coincide con la categoría de la oferta.\n",
        "- `label = 0` en caso contrario.\n",
        "\n",
        "Este etiquetado permite entrenar el modelo como una tarea de clasificación binaria, donde el objetivo es predecir si un par es un \"match\" (coincidente) o no.  \n",
        "Se imprime además la distribución de clases para verificar el balance del dataset resultante."
      ],
      "metadata": {
        "id": "ebS8QeOtrmOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pairs = make_pairs(df_cvs, offers)"
      ],
      "metadata": {
        "id": "nWVJZPPVSD8K"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verificación de la distribución"
      ],
      "metadata": {
        "id": "hZoayIh0iilY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── VERIFICACIÓN FINAL ──────────────────────────────────────────────────\n",
        "print(\"CVs cargados:\", len(df_cvs))\n",
        "print(\"Ofertas cargadas:\", len(offers))\n",
        "print(\"Total de pares generados:\", len(pairs))\n",
        "print(\"Distribución de clases (label):\")\n",
        "print(pairs['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07UWpfzf5-Dw",
        "outputId": "45d1da09-b388-43cd-b96f-40afcd1a0a21"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CVs cargados: 72\n",
            "Ofertas cargadas: 19\n",
            "Total de pares generados: 1368\n",
            "Distribución de clases (label):\n",
            "label\n",
            "0    1024\n",
            "1     344\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. División del Dataset y Preprocesamiento"
      ],
      "metadata": {
        "id": "zVkaNWv5ipw-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split de entrenamiento y validación"
      ],
      "metadata": {
        "id": "NI-SNljujRqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se divide el dataset en entrenamiento y validación, asegurando que no haya CVs duplicados entre ambos conjuntos.  \n",
        "La división se hace a nivel de `cv_id`, manteniendo el 80% para entrenamiento y el 20% para validación.\n",
        "\n",
        "Después, se realiza una limpieza básica del texto tanto en los CVs como en las ofertas:\n",
        "- Se eliminan tildes y signos de puntuación.\n",
        "- Se convierte todo a minúsculas.\n",
        "- Se normalizan los espacios.\n",
        "\n",
        "Esta limpieza estandariza el texto y reduce ruido para mejorar la calidad del entrenamiento posterior."
      ],
      "metadata": {
        "id": "Txy13qYgr_XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── SPLIT DE ENTRENAMIENTO Y VALIDACIÓN ─────────────────────────────────\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, ndcg_score\n",
        "\n",
        "# Dividimos el dataset de pares con labels (80% train, 20% valid)\n",
        "unique_cvs = pairs['cv_id'].unique()\n",
        "cv_train_ids, cv_val_ids = train_test_split(unique_cvs, test_size=0.2, random_state=42)\n",
        "\n",
        "pairs_train = pairs[pairs['cv_id'].isin(cv_train_ids)].copy()\n",
        "pairs_val = pairs[pairs['cv_id'].isin(cv_val_ids)].copy()\n",
        "\n",
        "print(f\"Pares para entrenamiento: {len(pairs_train)}\")\n",
        "print(f\"Pares para validación: {len(pairs_val)}\")\n",
        "print(\"Distribución en train:\")\n",
        "print(pairs_train['label'].value_counts())\n",
        "print(\"Distribución en validación:\")\n",
        "print(pairs_val['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DeW5kTC7224",
        "outputId": "d23a17a0-5877-48e0-fbea-883e1a2d317f"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pares para entrenamiento: 1083\n",
            "Pares para validación: 285\n",
            "Distribución en train:\n",
            "label\n",
            "0    812\n",
            "1    271\n",
            "Name: count, dtype: int64\n",
            "Distribución en validación:\n",
            "label\n",
            "0    212\n",
            "1     73\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Limpieza de texto"
      ],
      "metadata": {
        "id": "1HknkrGS9kKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def limpiar_texto(texto):\n",
        "    # Eliminar tildes y normalizar unicode\n",
        "    texto = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "\n",
        "    # Pasar a minúsculas\n",
        "    texto = texto.lower()\n",
        "\n",
        "    # Sustituir signos de puntuación por espacios\n",
        "    texto = re.sub(r\"[\\.,;:!\\?()\\[\\]\\\"']\", \" \", texto)\n",
        "\n",
        "    # Sustituir múltiples espacios por uno\n",
        "    texto = re.sub(r\"\\s+\", \" \", texto).strip()\n",
        "\n",
        "    return texto"
      ],
      "metadata": {
        "id": "xvC7kQZslREi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── IMPORTACIONES ────────────────────────────────────────────────────────\n",
        "import re\n",
        "import unicodedata\n",
        "from tqdm import tqdm\n",
        "\n",
        "tqdm.pandas()\n"
      ],
      "metadata": {
        "id": "UbBr-BXK90Gf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── APLICAMOS LIMPIEZA AL DATASET DE PARES ──────────────────────────────\n",
        "for campo in ['cv_text', 'offer_text']:\n",
        "    print(f\"Limpiando campo: {campo}\")\n",
        "    pairs_train[campo] = pairs_train[campo].progress_apply(limpiar_texto)\n",
        "    pairs_val[campo] = pairs_val[campo].progress_apply(limpiar_texto)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKITbpGt9-DD",
        "outputId": "ebb8a620-3211-4e92-c221-66fa2e72c130"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Limpiando campo: cv_text\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1083/1083 [00:00<00:00, 4246.29it/s]\n",
            "100%|██████████| 285/285 [00:00<00:00, 4430.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Limpiando campo: offer_text\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1083/1083 [00:00<00:00, 4088.95it/s]\n",
            "100%|██████████| 285/285 [00:00<00:00, 4320.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Truncado y augmentación"
      ],
      "metadata": {
        "id": "QIWqEWr8jkD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def truncar_texto(texto, max_tokens=MAX_TOKENS):\n",
        "    tokens = texto.split()\n",
        "    if len(tokens) > max_tokens:\n",
        "        return \" \".join(tokens[:max_tokens])\n",
        "    else:\n",
        "        return texto\n",
        "\n",
        "def permutar_frases(texto):\n",
        "    import random, re\n",
        "    frases = [f.strip() for f in re.split(r\"[\\.!?]\", texto) if f.strip()]\n",
        "    if len(frases) <= 1:\n",
        "        return texto  # no permutamos si no hay más de una frase\n",
        "    random.shuffle(frases)\n",
        "    return \". \".join(frases) + \".\"\n",
        "\n",
        "def augment_train(pairs):\n",
        "    pos = pairs[pairs.label==1].copy()\n",
        "    pos['cv_text'] = pos['cv_text'].apply(permutar_frases)\n",
        "    pos['offer_text'] = pos['offer_text'].apply(permutar_frases)\n",
        "    pos['cv_id']    = pos['cv_id'] + \"_aug\"\n",
        "    pos['offer_id'] = pos['offer_id'] + \"_aug\"\n",
        "    return pd.concat([pairs, pos], ignore_index=True)"
      ],
      "metadata": {
        "id": "ihBaPKhTlY1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se aplican dos transformaciones clave sobre los textos:\n",
        "\n",
        "1. **Truncado de texto**: se limitan los CVs y ofertas a un máximo de `MAX_TOKENS` palabras. Esto evita entradas excesivamente largas que podrían desbordar la memoria durante el entrenamiento.\n",
        "\n",
        "2. **Aumento de datos (data augmentation)**: se duplican los pares positivos (`label = 1`) generando una nueva versión donde se permutan aleatoriamente las frases del CV y de la oferta.  \n",
        "   Esto introduce variabilidad en el orden del contenido sin alterar su significado, lo que ayuda a mejorar la robustez del modelo.\n",
        "\n",
        "Los nuevos ejemplos se identifican con sufijos `_aug` en sus `cv_id` y `offer_id`."
      ],
      "metadata": {
        "id": "HhRO2In5sLT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── TRUNCADO DE TEXTOS LARGOS ─────────────────────────────────\n",
        "\n",
        "for campo in ['cv_text', 'offer_text']:\n",
        "    pairs_train[campo] = pairs_train[campo].apply(truncar_texto)\n",
        "    pairs_val[campo] = pairs_val[campo].apply(truncar_texto)\n"
      ],
      "metadata": {
        "id": "fndKxNHM-BeH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── AUGMENT TRAIN ─────────────────────────────────────────────────────────\n",
        "pairs_train = augment_train(pairs_train)\n",
        "\n",
        "print(f\"Nuevo tamaño de pairs_train tras augmentación: {len(pairs_train)}\")\n",
        "print(\"Distribución tras augmentación:\")\n",
        "print(pairs_train['label'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZxX9pM_A2QF",
        "outputId": "65d98bc0-f40a-4d30-96a8-cb75a83ca91e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nuevo tamaño de pairs_train tras augmentación: 1354\n",
            "Distribución tras augmentación:\n",
            "label\n",
            "0    812\n",
            "1    542\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Guardado de pares limpios"
      ],
      "metadata": {
        "id": "dxsDTRSwj3tD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── GUARDAR COPIAS PREPROCESADAS ──────────────────────────────\n",
        "pairs_train.to_csv(os.path.join(BASE_PATH, \"pairs_train_clean.csv\"), index=False)\n",
        "pairs_val.to_csv(os.path.join(BASE_PATH, \"pairs_val_clean.csv\"), index=False)\n"
      ],
      "metadata": {
        "id": "FfKQ7VDR-HP_"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenización"
      ],
      "metadata": {
        "id": "U34XVbD8-lr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def construir_vocab(textos, vocab_size=8000, min_freq=2):\n",
        "    c = Counter()\n",
        "    for t in textos: c.update(t.split())\n",
        "    vocab = {'<PAD>':0,'<UNK>':1}\n",
        "    idx = 2\n",
        "    for tok,f in c.most_common():\n",
        "        if f < min_freq or len(vocab)>=vocab_size: break\n",
        "        vocab[tok] = idx; idx+=1\n",
        "    return vocab\n",
        "\n",
        "def text_to_indices(texto, vocab, max_len=300):\n",
        "    tokens = texto.split()[:max_len]\n",
        "    ids = [vocab.get(tok, vocab['<UNK>']) for tok in tokens]\n",
        "    ids += [vocab['<PAD>']] * (max_len-len(ids))\n",
        "    return ids\n",
        "\n",
        "def tokenize_pairs(pairs, vocab):\n",
        "    df = pairs.copy()\n",
        "    df['cv_input_ids']    = df['cv_text'].apply(lambda t: text_to_indices(t, vocab))\n",
        "    df['offer_input_ids'] = df['offer_text'].apply(lambda t: text_to_indices(t, vocab))\n",
        "    return df"
      ],
      "metadata": {
        "id": "GeAqKvjalie4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se construye el vocabulario del modelo a partir de todos los textos de CVs y ofertas (entrenamiento y validación), limitando el tamaño máximo del vocabulario y filtrando por frecuencia mínima.\n",
        "\n",
        "Con ese vocabulario, se tokenizan los textos:\n",
        "- Cada palabra se convierte en su índice correspondiente.\n",
        "- Se aplica padding o truncado para que todos los ejemplos tengan la misma longitud.\n",
        "\n",
        "El resultado es un dataset preparado para alimentar directamente a una red neuronal."
      ],
      "metadata": {
        "id": "W22oV-Vls53y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── 1. CONSTRUIR EL VOCABULARIO SOBRE TODOS LOS TEXTOS ─────────────────────\n",
        "# Concatenamos todos los textos de CVs y ofertas (train y val)\n",
        "todos_los_textos = pd.concat([\n",
        "    pairs_train['cv_text'],\n",
        "    pairs_train['offer_text'],\n",
        "    pairs_val['cv_text'],\n",
        "    pairs_val['offer_text']\n",
        "])\n",
        "\n",
        "# Construimos vocabulario\n",
        "vocab = construir_vocab(todos_los_textos, vocab_size=8000, min_freq=2)\n",
        "\n",
        "print(f\"Vocabulario creado con {len(vocab)} tokens.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsZOX7a9-quK",
        "outputId": "07c2abd1-1fcc-4458-c350-999bb37d4374"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulario creado con 2631 tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pairs_train_tokenized = tokenize_pairs(pairs_train, vocab)\n",
        "pairs_val_tokenized = tokenize_pairs(pairs_val, vocab)\n",
        "\n",
        "print(f\"Pairs train tokenized shape: {pairs_train_tokenized.shape}\")\n",
        "print(f\"Pairs val tokenized shape: {pairs_val_tokenized.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPm1A4dGVcW1",
        "outputId": "284c352f-7139-43b9-cc2e-7bc30bd2bba3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pairs train tokenized shape: (1354, 9)\n",
            "Pairs val tokenized shape: (285, 9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "✅ La tokenización se ha aplicado correctamente: cada par CV–oferta tiene ahora sus representaciones en índices (`cv_input_ids` y `offer_input_ids`), listas para ser usadas en el modelo.\n",
        "\n",
        "Ambos datasets (`train` y `val`) contienen 9 columnas, lo que indica que conservan los campos originales más los tokens generados.\n"
      ],
      "metadata": {
        "id": "V_6NEOgMtMoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Arquitectura del Modelo"
      ],
      "metadata": {
        "id": "DRxqw7lVB_91"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición del encoder CNN-LSTM"
      ],
      "metadata": {
        "id": "H7wOiio6l4Gy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SiameseEncoderCNNLSTM**:  \n",
        "   Este encoder transforma una secuencia de tokens en una representación vectorial.  \n",
        "   Su estructura combina:\n",
        "   - Una capa de embeddings.\n",
        "   - Una convolución 1D para extraer patrones locales.\n",
        "   - Una LSTM bidireccional que captura dependencias a largo plazo.\n",
        "   - Un max-pooling global para obtener una representación fija del texto."
      ],
      "metadata": {
        "id": "m-ZFuULjtegm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseEncoderCNNLSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=128, conv_out=64, lstm_hidden=128, dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
        "        self.conv = nn.Conv1d(in_channels=emb_dim,\n",
        "                              out_channels=conv_out,\n",
        "                              kernel_size=5,\n",
        "                              padding=2)\n",
        "        self.lstm = nn.LSTM(input_size=conv_out,\n",
        "                            hidden_size=lstm_hidden,\n",
        "                            num_layers=1,\n",
        "                            batch_first=True,\n",
        "                            bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, L)\n",
        "        x = self.embedding(x)               # (B, L, E)\n",
        "        x = x.transpose(1,2)                # (B, E, L)\n",
        "        c = F.relu(self.conv(x))            # (B, C, L)\n",
        "        c = c.transpose(1,2)                # (B, L, C)\n",
        "        o, _ = self.lstm(c)                 # (B, L, 2*H)\n",
        "        o_max, _ = o.max(dim=1)             # (B, 2*H)\n",
        "        return self.dropout(o_max)"
      ],
      "metadata": {
        "id": "sMIZKvtzl8ex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo Siamese con MLP final"
      ],
      "metadata": {
        "id": "RjRt732vkGNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SiameseSimilarityModelEnhanced**:  \n",
        "   Recibe dos secuencias (CV y oferta), genera sus representaciones con el encoder, las concatena y las pasa por un pequeño MLP que aprende una función de similitud.  \n",
        "   La salida final es un valor ∈ [0,1] interpretado como score de adecuación."
      ],
      "metadata": {
        "id": "V4CFcfDOtip6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseSimilarityModelEnhanced(nn.Module):\n",
        "    def __init__(self, vocab_size, encoder_cls, encoder_kwargs, seq_len=300):\n",
        "        super().__init__()\n",
        "        self.encoder = encoder_cls(vocab_size, **encoder_kwargs)\n",
        "        # Medimos D_enc usando un tensor de prueba\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, seq_len, dtype=torch.long)\n",
        "            D_enc = self.encoder(dummy).shape[1]\n",
        "\n",
        "        # Ahora construimos el MLP con las dimensiones correctas\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(2 * D_enc, D_enc),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(encoder_kwargs.get('dropout', 0.3)),\n",
        "            nn.Linear(D_enc, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, a, b):\n",
        "      va = self.encoder(a)                    # (B, D_enc)\n",
        "      vb = self.encoder(b)                    # (B, D_enc)\n",
        "      x  = torch.cat([va, vb], dim=1)         # (B, 2*D_enc)\n",
        "      return self.mlp(x).squeeze(1)           # (B,)"
      ],
      "metadata": {
        "id": "1KDkHV45l-c1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hiperparámetros y construcción del modelo"
      ],
      "metadata": {
        "id": "DjlafGnCmFOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se definen los hiperparámetros clave del encoder: dimensión de embeddings, tamaño de los filtros convolucionales, dimensión oculta del LSTM y tasa de dropout.\n",
        "\n",
        "A continuación, se instancia el modelo `SiameseSimilarityModelEnhanced`, indicando la clase de encoder y los parámetros definidos.  \n",
        "El modelo se mueve a GPU si está disponible (`\"cuda\"`)."
      ],
      "metadata": {
        "id": "SK1ezmIAt063"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(vocab)  # el vocabulario que creaste en Fase 1\n",
        "\n",
        "# Definición del encoder “mejorado”\n",
        "encoder_kwargs = {\n",
        "    'emb_dim':      128,\n",
        "    'conv_out':     64,\n",
        "    'lstm_hidden':  128,\n",
        "    'dropout':      0.3\n",
        "}\n",
        "\n",
        "# Creas el modelo pasándole la clase del encoder y sus argumentos\n",
        "model = SiameseSimilarityModelEnhanced(\n",
        "    vocab_size   = VOCAB_SIZE,\n",
        "    encoder_cls  = SiameseEncoderCNNLSTM,\n",
        "    encoder_kwargs = encoder_kwargs\n",
        ").to(\"cuda\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MEZpCLkXCTAl"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pérdida y optimizador"
      ],
      "metadata": {
        "id": "c_UIt-cSCgOp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "También se establece:\n",
        "- La **función de pérdida** como entropía binaria (`BCELoss`), apropiada para una salida ∈ [0,1].\n",
        "- El **optimizador** como `AdamW`, que incorpora regularización mediante decaimiento del peso (`weight_decay`), útil para evitar overfitting."
      ],
      "metadata": {
        "id": "R2lSNQo3t5D3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creamos la función de pérdida\n",
        "from torch import nn\n",
        "\n",
        "loss_fn = nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "DSDFJGxnCjr-"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n"
      ],
      "metadata": {
        "id": "-4vUO9f0Cou1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Entrenamiento del Modelo"
      ],
      "metadata": {
        "id": "8jVkc0J8mbmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset y DataLoaders"
      ],
      "metadata": {
        "id": "bB8uAyU9mfMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "class PairsDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.cv_ids    = df['cv_input_ids'].tolist()\n",
        "        self.offer_ids = df['offer_input_ids'].tolist()\n",
        "        self.labels    = df['label'].tolist()\n",
        "    def __len__(self): return len(self.labels)\n",
        "    def __getitem__(self,i):\n",
        "        return {\n",
        "            'cv_input_ids':    torch.tensor(self.cv_ids[i], dtype=torch.long),\n",
        "            'offer_input_ids': torch.tensor(self.offer_ids[i], dtype=torch.long),\n",
        "            'label':           torch.tensor(self.labels[i], dtype=torch.float)\n",
        "        }"
      ],
      "metadata": {
        "id": "35UaxoOlmzG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Primero se define una clase `PairsDataset` que convierte el DataFrame tokenizado en un dataset compatible con PyTorch.  \n",
        "Luego se crean los `DataLoader` para entrenamiento y validación."
      ],
      "metadata": {
        "id": "XK4AZRQFuC7B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "train_dataset = PairsDataset(pairs_train_tokenized)\n",
        "val_dataset = PairsDataset(pairs_val_tokenized)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64)\n"
      ],
      "metadata": {
        "id": "BWrHme2VCsU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funciones de entrenamiento y evaluación"
      ],
      "metadata": {
        "id": "i70Wyqg3nEFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos todas las métricas necesarias\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, classification_report\n",
        "\n",
        "def evaluate_classification(y_true, y_pred_proba, threshold=0.5):\n",
        "    \"\"\"\n",
        "    Evalúa las métricas básicas de clasificación dado un umbral sobre el score.\n",
        "    \"\"\"\n",
        "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
        "\n",
        "    print(f\"Evaluación con umbral = {threshold}\")\n",
        "    print(\"- Accuracy:\", accuracy_score(y_true, y_pred))\n",
        "    print(\"- F1 Score:\", f1_score(y_true, y_pred))\n",
        "    print(\"- Precision:\", precision_score(y_true, y_pred))\n",
        "    print(\"- Recall:\", recall_score(y_true, y_pred))\n",
        "    print(\"- AUC:\", roc_auc_score(y_true, y_pred_proba))\n",
        "    print(\"- Clasification report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "def train_model(model,\n",
        "                pairs_train_df,\n",
        "                pairs_val_df,\n",
        "                device='cuda',\n",
        "                epochs=50,\n",
        "                patience=4,\n",
        "                show_every=10,\n",
        "                threshold=0.7,\n",
        "                save_path=\"/content/drive/MyDrive/TFM/red_neuronal/modelo_mejor.pt\"):\n",
        "    \"\"\"\n",
        "    Entrena el modelo siamés con early stopping y logging controlado.\n",
        "\n",
        "    Args:\n",
        "      model: instancia de SiameseSimilarityModel ya movida a `device`.\n",
        "      pairs_train_df: DataFrame tokenizado para entrenamiento.\n",
        "      pairs_val_df:   DataFrame tokenizado para validación.\n",
        "      device: 'cuda' o 'cpu'.\n",
        "      epochs: número máximo de épocas.\n",
        "      patience: épocas sin mejora para parar.\n",
        "      show_every: cada cuántas épocas imprimir métricas.\n",
        "      threshold: umbral para clasificación de y_pred en f1_score.\n",
        "      save_path: ruta donde guardar el mejor modelo.\n",
        "    \"\"\"\n",
        "    # 1) Prepara DataLoaders\n",
        "    class PairsDataset(Dataset):\n",
        "        def __init__(self, df):\n",
        "            self.cv_ids    = df['cv_input_ids'].tolist()\n",
        "            self.offer_ids = df['offer_input_ids'].tolist()\n",
        "            self.labels    = df['label'].tolist()\n",
        "        def __len__(self): return len(self.labels)\n",
        "        def __getitem__(self, i):\n",
        "            return {\n",
        "                'cv_input_ids':    torch.tensor(self.cv_ids[i], dtype=torch.long),\n",
        "                'offer_input_ids': torch.tensor(self.offer_ids[i], dtype=torch.long),\n",
        "                'label':           torch.tensor(self.labels[i], dtype=torch.float)\n",
        "            }\n",
        "\n",
        "    train_loader = DataLoader(PairsDataset(pairs_train_df), batch_size=32, shuffle=True)\n",
        "    val_loader   = DataLoader(PairsDataset(pairs_val_df),   batch_size=64)\n",
        "\n",
        "    # 2) Pérdida y optimizador\n",
        "    loss_fn   = torch.nn.BCELoss()\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "\n",
        "    best_f1 = 0.0\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(1, epochs+1):\n",
        "        # --- Entrenamiento de una época ---\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        for batch in train_loader:\n",
        "            cv_in  = batch['cv_input_ids'].to(device)\n",
        "            ofr_in = batch['offer_input_ids'].to(device)\n",
        "            lbl    = batch['label'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            preds = model(cv_in, ofr_in)\n",
        "            loss  = loss_fn(preds, lbl)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # --- Evaluación en validación ---\n",
        "        model.eval()\n",
        "        all_y, all_p = [], []\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                cv_in  = batch['cv_input_ids'].to(device)\n",
        "                ofr_in = batch['offer_input_ids'].to(device)\n",
        "                lbl    = batch['label'].to(device)\n",
        "                preds  = model(cv_in, ofr_in)\n",
        "                all_y.extend(lbl.cpu().numpy())\n",
        "                all_p.extend(preds.cpu().numpy())\n",
        "\n",
        "        # Convertimos a numpy arrays para poder hacer comparacion con threshold\n",
        "        all_y = np.array(all_y)\n",
        "        all_p = np.array(all_p)\n",
        "\n",
        "        # Cálculo de F1\n",
        "        f1 = f1_score(all_y, (np.array(all_p) >= threshold).astype(int))\n",
        "\n",
        "        # Early stopping & guardado del mejor modelo\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            epochs_without_improvement = 0\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        # Logging controlado\n",
        "        if epoch % show_every == 0 or epoch == epochs:\n",
        "            print(f\"\\n🔁 Epoch {epoch}/{epochs} | Train Loss: {train_loss:.4f} | F1: {f1:.4f}\")\n",
        "            evaluate_classification(all_y, all_p, threshold=threshold)\n",
        "\n",
        "        # Comprueba early stopping\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"\\n⏹️ Early stopping en epoch {epoch} (sin mejora en {patience} epochs).\")\n",
        "            break\n",
        "\n",
        "    print(f\"\\n🏁 Entrenamiento finalizado. Mejor F1 obtenida: {best_f1:.4f}\")\n",
        "    # Carga el mejor modelo guardado\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    return model"
      ],
      "metadata": {
        "id": "I2wf0xXnm6zV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La función `train_model` encapsula todo el proceso de entrenamiento:\n",
        "\n",
        "- Usa `BCELoss` como función de pérdida y `AdamW` como optimizador.\n",
        "- Entrena durante un número máximo de épocas (`epochs`), pero detiene anticipadamente si el F1 no mejora tras `patience` épocas.\n",
        "- Evalúa tras cada época usando métricas clásicas (F1, precisión, recall, AUC).\n",
        "- Guarda el modelo con mejor F1 en el archivo indicado (`save_path`).\n",
        "- Devuelve el modelo ya cargado con los pesos óptimos.\n",
        "\n",
        "Este diseño permite entrenar y validar el modelo de forma controlada y reproducible, incluyendo logs periódicos e interrupción automática si no hay progreso."
      ],
      "metadata": {
        "id": "KXM9jHTpuGbT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ejecución del entrenamiento"
      ],
      "metadata": {
        "id": "VAyAx2y3na26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se lanza el entrenamiento del modelo utilizando la función `train_model`.\n",
        "\n",
        "- Se detecta automáticamente si hay GPU disponible (`\"cuda\"`).\n",
        "- Se especifican hiperparámetros clave como:\n",
        "  - `epochs`: número máximo de épocas de entrenamiento.\n",
        "  - `patience`: número de épocas sin mejora tras las cuales se activa el early stopping.\n",
        "  - `threshold`: umbral para considerar un score como positivo en las métricas.\n",
        "  - `show_every`: frecuencia con la que se imprime el estado de entrenamiento.\n",
        "  - `save_path`: ruta donde se guarda el mejor modelo encontrado.\n",
        "\n",
        "El modelo devuelto ya contiene los pesos entrenados óptimos según el F1 en validación."
      ],
      "metadata": {
        "id": "VamBitpCuPSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# Entrenamos\n",
        "model = train_model(\n",
        "    model,\n",
        "    pairs_train_df = pairs_train_tokenized,\n",
        "    pairs_val_df   = pairs_val_tokenized,\n",
        "    device         = device,\n",
        "    epochs         = 5,\n",
        "    patience       = 2,\n",
        "    show_every     = 2,\n",
        "    threshold      = 0.25,\n",
        "    save_path      = \"/content/drive/MyDrive/TFM/red_neuronal/modelo_mejor.pt\"\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARrcw7raC085",
        "outputId": "eff5f42f-b9ae-48f2-8dc1-fede2a04c528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔁 Epoch 5/25 | Train Loss: 0.6623 | F1: 0.4257\n",
            "Evaluación con umbral = 0.25\n",
            "- Accuracy: 0.3087719298245614\n",
            "- F1 Score: 0.42565597667638483\n",
            "- Precision: 0.27037037037037037\n",
            "- Recall: 1.0\n",
            "- AUC: 0.6389894029464978\n",
            "- Clasification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.07      0.13       212\n",
            "         1.0       0.27      1.00      0.43        73\n",
            "\n",
            "    accuracy                           0.31       285\n",
            "   macro avg       0.64      0.54      0.28       285\n",
            "weighted avg       0.81      0.31      0.21       285\n",
            "\n",
            "\n",
            "🔁 Epoch 10/25 | Train Loss: 0.0069 | F1: 0.7682\n",
            "Evaluación con umbral = 0.25\n",
            "- Accuracy: 0.8771929824561403\n",
            "- F1 Score: 0.7682119205298014\n",
            "- Precision: 0.7435897435897436\n",
            "- Recall: 0.7945205479452054\n",
            "- AUC: 0.9254975445851641\n",
            "- Clasification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.91      0.92       212\n",
            "         1.0       0.74      0.79      0.77        73\n",
            "\n",
            "    accuracy                           0.88       285\n",
            "   macro avg       0.84      0.85      0.84       285\n",
            "weighted avg       0.88      0.88      0.88       285\n",
            "\n",
            "\n",
            "⏹️ Early stopping en epoch 13 (sin mejora en 5 epochs).\n",
            "\n",
            "🏁 Entrenamiento finalizado. Mejor F1 obtenida: 0.7975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Durante el entrenamiento se observa una evolución clara de las métricas:\n",
        "\n",
        "- En la **época 5**, el modelo aún no distingue correctamente entre clases. La F1 es baja, el accuracy es inferior al 31%, y aunque el recall es 1.0, la precisión es muy baja (el modelo predice muchos falsos positivos).\n",
        "- En la **época 10**, el modelo mejora significativamente. La F1 sube a 0.77, con buena precisión y recall balanceados. El AUC también es alto (0.93), lo que indica que el modelo discrimina bien entre clases.\n",
        "\n",
        "El entrenamiento se detuvo automáticamente en la época 13 mediante **early stopping**, al no detectarse mejora durante 5 épocas consecutivas.  \n",
        "El mejor modelo se guardó con un **F1 óptimo de 0.7975**.\n",
        "\n",
        "Estos resultados sugieren que el modelo ha aprendido una representación efectiva y es capaz de generalizar razonablemente bien sobre los datos de validación."
      ],
      "metadata": {
        "id": "D2umG-I8uXzz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Evaluación y Calibración"
      ],
      "metadata": {
        "id": "HWxp7uymn59M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación del modelo entrenado y Calibración con Platt Scaling"
      ],
      "metadata": {
        "id": "gQVTAojXn-aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, loader, device='cuda'):\n",
        "    \"\"\"\n",
        "    Ejecuta evaluación del modelo sobre un DataLoader.\n",
        "    Devuelve:\n",
        "      - y_true: etiquetas reales (array)\n",
        "      - y_pred: scores ∈ [0,1] del modelo (array)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_y = []\n",
        "    all_p = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            cv_input  = batch['cv_input_ids'].to(device)\n",
        "            ofr_input = batch['offer_input_ids'].to(device)\n",
        "            labels    = batch['label'].to(device)\n",
        "\n",
        "            preds = model(cv_input, ofr_input)  # salida ∈ [0,1]\n",
        "            all_y.extend(labels.cpu().numpy())\n",
        "            all_p.extend(preds.cpu().numpy())\n",
        "\n",
        "    return np.array(all_y), np.array(all_p)\n"
      ],
      "metadata": {
        "id": "Mot9bXTXoEfV"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define la función `evaluate` para obtener las predicciones del modelo sobre un `DataLoader`, devolviendo tanto las etiquetas reales (`y_true`) como los scores crudos (`y_pred`) en el rango [0,1].\n",
        "\n",
        "A continuación, se aplica **Platt Scaling**, un método clásico de calibración de probabilidades. Consiste en ajustar una regresión logística sobre los scores del modelo para que las salidas se interpreten como probabilidades calibradas.\n",
        "\n",
        "Se entrena este calibrador sobre las predicciones del conjunto de validación. El parámetro `C` controla la regularización: un valor más bajo produce una curva de calibración más suave.  \n",
        "El calibrador entrenado se guarda en disco para su uso posterior en la inferencia sobre datos de test."
      ],
      "metadata": {
        "id": "VXATXc70uo_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "def calibrate_platt(y_true, y_raw, save_path, C=0.1, max_iter=1000):\n",
        "    \"\"\"\n",
        "    Entrena un calibrador Platt (LogisticRegression) con regularización fuerte.\n",
        "\n",
        "    Args:\n",
        "      y_true:  array de etiquetas {0,1}.\n",
        "      y_raw:   array de scores bruto ∈ [0,1].\n",
        "      save_path: ruta donde guardar el calibrador.\n",
        "      C:        inverso de fuerza de regularización (C pequeño → más regularización).\n",
        "      max_iter: iteraciones máximas para converger.\n",
        "    \"\"\"\n",
        "    # 1) Aseguramos que trabajamos con numpy arrays\n",
        "    X = np.array(y_raw).reshape(-1,1)\n",
        "    y = np.array(y_true)\n",
        "\n",
        "    # 2) Creamos y entrenamos el calibrador con C pequeño\n",
        "    lr = LogisticRegression(solver='lbfgs', C=C, max_iter=max_iter)\n",
        "    lr.fit(X, y)\n",
        "\n",
        "    # 3) Guardamos el calibrador\n",
        "    joblib.dump(lr, save_path)\n",
        "    return lr"
      ],
      "metadata": {
        "id": "N415T2JYpakb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Eval final\n",
        "y_true, y_pred = evaluate(model, val_loader)\n",
        "\n",
        "# Calibrar el modelo con Platt Scaling\n",
        "platt = calibrate_platt(y_true, y_pred, save_path=\"/content/drive/MyDrive/TFM/red_neuronal/platt_scaling.joblib\", C=10)\n"
      ],
      "metadata": {
        "id": "vMmtwKdaX7ya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Histogramas de calibración"
      ],
      "metadata": {
        "id": "xmASGq8eoShq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_offers_for_cv_calibrated(cv_input_ids, offer_input_ids, model, platt, top_n=5):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        cv_input_ids = cv_input_ids.to(\"cuda\")\n",
        "        offer_input_ids = offer_input_ids.to(\"cuda\")\n",
        "        if cv_input_ids.shape[0] == 1:\n",
        "            cv_input_ids = cv_input_ids.expand(offer_input_ids.size(0), -1)\n",
        "\n",
        "        # 2.2 Obtén score bruto ∈ [0,1]\n",
        "        raw_scores = model(cv_input_ids, offer_input_ids).cpu().numpy()\n",
        "        # 2.3 Calibra con Platt Scaling\n",
        "        prob_scores = platt.predict_proba(raw_scores.reshape(-1, 1))[:, 1]\n",
        "        # 2.4 Pasa a porcentaje\n",
        "        pct_scores = prob_scores * 100\n",
        "\n",
        "    # 2.5 Ranking top-n\n",
        "    top_idxs = pct_scores.argsort()[::-1][:top_n]\n",
        "    return top_idxs, pct_scores"
      ],
      "metadata": {
        "id": "0jY2YMRRpgLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se define una función `rank_offers_for_cv_calibrated` que toma un CV y un conjunto de ofertas, calcula los scores crudos con el modelo y los calibra usando el modelo de Platt Scaling previamente entrenado.\n",
        "\n",
        "Los scores calibrados (probabilidades) se transforman a porcentajes para facilitar su interpretación.\n",
        "\n",
        "Después:\n",
        "- Se selecciona un CV específico del conjunto de validación.\n",
        "- Se convierte su texto en índices.\n",
        "- Se tokenizan todas las ofertas de validación.\n",
        "- Se ejecuta la función de ranking para obtener las ofertas más adecuadas ordenadas por su score calibrado.\n",
        "\n",
        "Se imprime el top-N de ofertas más relevantes para ese CV, mostrando tanto el score como un extracto del texto de la oferta."
      ],
      "metadata": {
        "id": "FYdNSSXmu5jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Seleccionar un CV por ID\n",
        "cv_id_objetivo = pairs_val_tokenized['cv_id'].iloc[0]\n",
        "cv_texto = pairs_val_tokenized[pairs_val_tokenized['cv_id'] == cv_id_objetivo]['cv_text'].iloc[0]\n"
      ],
      "metadata": {
        "id": "zg-UoRmtLva4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertimos el texto a indices con tu vocab y padding\n",
        "cv_indices = text_to_indices(cv_texto, vocab, max_len=300)\n",
        "cv_tensor = torch.tensor([cv_indices], dtype=torch.long)  # (1, seq_len)\n"
      ],
      "metadata": {
        "id": "tMmmMm9jLxHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponemos que tienes este DataFrame con ofertas de validación\n",
        "df_ofertas = pairs_val_tokenized[['offer_id', 'offer_text']].drop_duplicates()\n",
        "\n",
        "# Tokenizar todas las ofertas a índices\n",
        "offer_tensors = [text_to_indices(text, vocab, max_len=300) for text in df_ofertas['offer_text']]\n",
        "offers_tensor = torch.tensor(offer_tensors, dtype=torch.long)  # (N, seq_len)\n"
      ],
      "metadata": {
        "id": "2qjamgQzLzMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_idxs, pct_scores = rank_offers_for_cv_calibrated(cv_tensor, offers_tensor, model, platt)\n",
        "\n",
        "for i in top_idxs:\n",
        "    texto = df_ofertas.iloc[i]['offer_text']\n",
        "    print(f\"{pct_scores[i]:.2f}% → {texto[:120]}...\")\n"
      ],
      "metadata": {
        "id": "XAn1eCrjLLGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132905f0-1c7d-4137-ede2-bb7e9c8f7785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.12% → acerca del empleo role splunk software engineer type of contract permanent working model hybrid 2 days in client office ...\n",
            "74.72% → acerca del empleo te entusiasta el analisis de datos y quieres ser parte de un proyecto que vuela alto en innovacion for...\n",
            "72.54% → acerca del empleo los ingenieros de software junior son profesionales tecnicamente capacitados con el deseo de disenar d...\n",
            "72.54% → acerca del empleo los ingenieros de software junior son profesionales tecnicamente capacitados con el deseo de disenar d...\n",
            "71.96% → acerca del empleo hola somos lis data solutions una ingenieria especializada en el analisis de datos que acompana y ayud...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = pairs_val_tokenized.copy()\n",
        "with torch.no_grad():\n",
        "    scores = model(\n",
        "        torch.tensor(list(df_val['cv_input_ids'])).to(\"cuda\"),\n",
        "        torch.tensor(list(df_val['offer_input_ids'])).to(\"cuda\")\n",
        "    ).detach().cpu().numpy() * 100\n",
        "\n",
        "df_val['score'] = scores\n",
        "df_val.sort_values(by='score', ascending=False).to_csv(\"/content/val_resultados_score.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "7P3_Gs90MUyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza una inferencia completa sobre el conjunto de validación, calculando los scores de adecuación entre cada par CV–oferta.  \n",
        "Los resultados se guardan en un archivo CSV ordenado por score descendente (`val_resultados_score.csv`), útil para análisis o inspección manual.\n",
        "\n",
        "A continuación, se aplica el calibrador Platt a los scores del modelo (`y_pred`) para visualizar la distribución de probabilidades calibradas.  \n",
        "El histograma permite observar si el modelo produce una separación clara entre clases y si la calibración suaviza o comprime los scores en rangos razonables de probabilidad."
      ],
      "metadata": {
        "id": "tmYZLkStvKal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Aplica calibración a tus y_pred crudos\n",
        "prob_scores = platt.predict_proba(y_pred.reshape(-1,1))[:,1]\n",
        "\n",
        "plt.hist(prob_scores, bins=30, color='skyblue')\n",
        "plt.title(\"Distribución de probabilidades calibradas (0–1)\")\n",
        "plt.xlabel(\"Probabilidad calibrada\")\n",
        "plt.ylabel(\"Frecuencia\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Z-OEud7zM3J-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "448acc72-d2c0-44bf-9984-f078493463e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La gráfica muestra la distribución de scores calibrados (probabilidades ∈ [0,1]) obtenidos tras aplicar Platt Scaling a los resultados del modelo.\n",
        "\n",
        "Se observan dos acumulaciones claras:\n",
        "- Una gran mayoría de pares tienen probabilidades muy bajas (cerca de 0.05–0.1), lo que indica que el modelo está seguro de que **no son un match**.\n",
        "- Un segundo grupo más pequeño, pero bien definido, se concentra en la zona alta (>0.8), indicando predicciones **positivas con alta confianza**.\n",
        "\n",
        "La escasez de valores en la zona intermedia sugiere que el modelo tiende a ser bastante decisivo, lo cual puede ser positivo para tareas de ranking si se prioriza precisión en el top-N.  \n",
        "Esta distribución también indica que la calibración ha suavizado adecuadamente los scores crudos sin colapsarlos a 0 o 1."
      ],
      "metadata": {
        "id": "YxdY9MuPvao2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Inferencia en CVs de Test"
      ],
      "metadata": {
        "id": "R98OfZYuvav6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carga y limpieza de los CVs de test"
      ],
      "metadata": {
        "id": "VNP8sIFivav7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importamos librerías\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "# ─── CARGA Y PREPROCESADO DE LOS CV DE TEST ────────────────────────────────\n",
        "test_path = os.path.join(BASE_PATH, \"cvs_test_preprocesado.csv\")\n",
        "df_test = pd.read_csv(test_path).rename(columns={'Texto extraído': 'cv_text', 'Nombre del archivo': 'cv_id'})\n",
        "\n",
        "# Limpieza y truncado\n",
        "df_test['cv_text'] = df_test['cv_text'].apply(limpiar_texto).apply(truncar_texto)"
      ],
      "metadata": {
        "id": "f-V5pNEnvav7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se realiza el preprocesado completo para aplicar el modelo a nuevos CVs sin etiqueta:\n",
        "\n",
        "1. **Carga de test**: se lee el archivo `cvs_test_preprocesado.csv`, renombrando las columnas relevantes."
      ],
      "metadata": {
        "id": "lEP1IhGYvly5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Combinación CV-oferta y Tokenización"
      ],
      "metadata": {
        "id": "4LFCUdoQvav7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── TOKENIZAMOS LOS CVS ───────────────────────────────────────────────────\n",
        "df_test['cv_input_ids'] = df_test['cv_text'].apply(lambda x: text_to_indices(x, vocab, max_len=300))\n",
        "\n",
        "# ─── PREPARAMOS EL DATASET DE OFERTAS ──────────────────────────────────────\n",
        "df_ofertas = offers.copy()  # Las ofertas ya estaban cargadas en tu flujo\n",
        "df_ofertas = df_ofertas.rename(columns={'offer_text': 'offer_text', 'offer_id': 'offer_id'})\n",
        "df_ofertas['offer_text'] = df_ofertas['offer_text'].apply(limpiar_texto).apply(truncar_texto)\n",
        "df_ofertas['offer_input_ids'] = df_ofertas['offer_text'].apply(lambda x: text_to_indices(x, vocab, max_len=300))"
      ],
      "metadata": {
        "id": "ys_OeBuqvav7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Limpieza y truncado**: se aplica la misma limpieza y limitación de longitud usada en entrenamiento, garantizando consistencia.\n",
        "\n",
        "3. **Tokenización**: los textos de los CVs y las ofertas se convierten a secuencias de índices utilizando el vocabulario previamente construido.\n",
        "\n",
        "4. **Producto cartesiano**: se generan todos los pares posibles `CV_test × Oferta`, creando el conjunto sobre el que se hará inferencia."
      ],
      "metadata": {
        "id": "QpJNKS5n4ZVX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── PRODUCTO CARTESIANO ENTRE TEST Y OFERTAS ──────────────────────────────\n",
        "df_test = df_test.assign(key=1)\n",
        "df_ofertas = df_ofertas.assign(key=1)\n",
        "pairs_test = df_test.merge(df_ofertas, on='key').drop('key', axis=1)"
      ],
      "metadata": {
        "id": "QmWXgBjSvav8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tensores"
      ],
      "metadata": {
        "id": "-ZlWQ303vav8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **Conversión a tensores**: las secuencias tokenizadas se convierten a tensores PyTorch para poder pasarlas al modelo en batch.\n",
        "\n",
        "Este bloque deja los datos completamente preparados para ejecutar el modelo y obtener los scores de adecuación."
      ],
      "metadata": {
        "id": "qQDEzhmb4hr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── CONVERSIÓN A TENSORES ─────────────────────────────────────────────────\n",
        "cv_tensor     = torch.tensor(list(pairs_test['cv_input_ids']), dtype=torch.long)\n",
        "offer_tensor  = torch.tensor(list(pairs_test['offer_input_ids']), dtype=torch.long)"
      ],
      "metadata": {
        "id": "q1mZPoM9vav8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predicción de scores calibrados"
      ],
      "metadata": {
        "id": "evyXVQ5-o8aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Inicializamos el modelo\n",
        "model = SiameseSimilarityModelEnhanced(\n",
        "    vocab_size   = VOCAB_SIZE,\n",
        "    encoder_cls  = SiameseEncoderCNNLSTM,\n",
        "    encoder_kwargs = encoder_kwargs\n",
        ").to(\"cuda\")\n",
        "\n",
        "# Load the saved model\n",
        "model.load_state_dict(torch.load(\"/content/drive/MyDrive/TFM/red_neuronal/modelo_mejor.pt\"))\n",
        "model.eval()\n",
        "\n",
        "# Load the Platt scaling calibrator\n",
        "platt = joblib.load(\"/content/drive/MyDrive/TFM/red_neuronal/platt_scaling.joblib\")\n"
      ],
      "metadata": {
        "id": "d8oMvS41enb7"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se carga el modelo entrenado (`modelo_mejor.pt`) y el calibrador de Platt (`platt_scaling.joblib`) para realizar inferencia sobre los pares `CV_test × Oferta`.\n",
        "\n",
        "- Se ejecuta el modelo en modo evaluación (`eval`) sin computar gradientes.\n",
        "- Los scores crudos del modelo (∈ [0,1]) se calibran con Platt Scaling para obtener probabilidades más fiables.\n",
        "- Se construye un DataFrame con los resultados, incluyendo el identificador del CV, el de la oferta, el texto de la oferta y el score calibrado."
      ],
      "metadata": {
        "id": "3MQFPEkI4_HW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── CÁLCULO DE SCORES CALIBRADOS ──────────────────────────────────────────\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    cv_tensor = cv_tensor.to(\"cuda\")\n",
        "    offer_tensor = offer_tensor.to(\"cuda\")\n",
        "\n",
        "    # Si no están del mismo tamaño, expande los CV (pero aquí ya están pareados)\n",
        "    raw_scores = model(cv_tensor, offer_tensor).cpu().numpy()\n",
        "    prob_scores = platt.predict_proba(raw_scores.reshape(-1,1))[:,1]"
      ],
      "metadata": {
        "id": "-bU8qYxvelTR"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── CONSTRUCCIÓN DEL DATAFRAME FINAL ──────────────────────────────────────\n",
        "df_resultados = pairs_test[['cv_id', 'offer_id', 'offer_text']].copy()\n",
        "df_resultados['score'] = prob_scores"
      ],
      "metadata": {
        "id": "If1NpnkHfGhp"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exportación de resultados"
      ],
      "metadata": {
        "id": "CZJ6X4xoo_Al"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finalmente, se exporta el ranking completo a un archivo CSV (`rankings_test_generado.csv`) que puede usarse para análisis o recomendaciones posteriores."
      ],
      "metadata": {
        "id": "pSml_0gH5H-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ─── EXPORTACIÓN A CSV ─────────────────────────────────────────────────────\n",
        "output_path = \"/content/drive/MyDrive/TFM/red_neuronal/rankings_test_generado.csv\"\n",
        "df_resultados.to_csv(output_path, index=False)\n",
        "\n",
        "print(\"✅ CSV generado con éxito:\", output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYQ-59eKfKcG",
        "outputId": "e103ebe2-10cd-46fc-dd7f-0a072bb0ac8d"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ CSV generado con éxito: /content/drive/MyDrive/TFM/red_neuronal/rankings_test_generado.csv\n"
          ]
        }
      ]
    }
  ]
}